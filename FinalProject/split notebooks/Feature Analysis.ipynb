{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../final_merge.csv')\n",
    "df['song_hotttnesss'] = df['song_hotttnesss'].fillna(0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put the dataframe in a good form for the rest of the analysis.\n",
    "\n",
    "First, we remove all useless column, or the one we don't want to describe a song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage1 = df.drop(['Unnamed: 0', 'artist_latitude', 'artist_location', 'artist_id', 'artist_longitude', 'song_id', 'track_id', 'artist_hotttnesss', 'mode_x', 'mode_y'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need a one hot encoded matrix for genre for future analysis. We need all the genres in a first time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = set([])\n",
    "genres_cols = ['genre1_cd2c', 'genre2_cd2c', 'genre1_cd2', 'genre2_cd2', 'genre1_cd1', 'genre2_cd1']\n",
    "for col_name in genres_cols:\n",
    "    genres = genres | set(df_stage1[col_name].unique())\n",
    "print(genres)\n",
    "print(len(genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 17 different genres (nan are unkownn and international is the same as world). To do a meaningful analysis of the genre analysis over the year a minimum amount of songs of the analyzed type must be in the dataset. In the following cells we first replace the nan and replace International by World. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage1[genres_cols] = df_stage1[genres_cols].fillna('Unknown')\n",
    "df_stage1[genres_cols] = df_stage1[genres_cols].replace('International', 'World')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's just check that we have the wanting form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_stage1[genres_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the moment we have 6 columns for the genres, we would like to see if we can summarize these columns in one or two columns.\n",
    "First we perform a pivot and count the number of different values there are in each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = set([])\n",
    "genres_cols = ['genre1_cd2c', 'genre2_cd2c', 'genre1_cd2', 'genre2_cd2', 'genre1_cd1', 'genre2_cd1']\n",
    "for col_name in genres_cols:\n",
    "    genres = genres | set(df_stage1[col_name].unique())\n",
    "    df_stage1[col_name] = df_stage1[col_name].astype(str)\n",
    "print(genres)\n",
    "print(len(genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in list(genres):\n",
    "    df_stage1[genre] = 0\n",
    "    for col_name in genres_cols:\n",
    "        df_stage1.loc[df_stage1[col_name] == genre, genre] = 1\n",
    "df_stage1.drop(columns=['Unknown'], axis=1, inplace=True)\n",
    "genres.remove('Unknown')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make sure we have a hot encoded matrix at the end now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_stage2 = df_stage1.drop(genres_cols, axis=1).copy()\n",
    "df_stage2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the matrix is ready, let's see if we can spot something from a simple correlation between the data, especially between song_hotttnesss and the rest of the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_corr(df, output_file_name):\n",
    "    '''\n",
    "        Plot the correlation matrix of a dataframe\n",
    "        The plot will be triangular with negative values blue and positive values red\n",
    "        Code taken from https://seaborn.pydata.org/examples/many_pairwise_correlations.html\n",
    "        :param df: The dataframe\n",
    "        :type df: DataFrame\n",
    "    '''\n",
    "    sns.set(style=\"white\", font_scale=1.5)\n",
    "\n",
    "    # Compute the correlation matrix\n",
    "    corr = df.corr()\n",
    "\n",
    "    # Generate a mask for the upper triangle\n",
    "    mask = np.zeros_like(corr, dtype=np.bool)\n",
    "    mask[np.triu_indices_from(mask)] = True\n",
    "\n",
    "    # Set up the matplotlib figure\n",
    "    f, ax = plt.subplots(figsize=(16, 12))\n",
    "    f.suptitle(\"Correlation heatmap\")\n",
    "\n",
    "    # Generate a custom diverging colormap\n",
    "    cmap = sns.diverging_palette(220, 10, as_cmap=True)\n",
    "\n",
    "    # Draw the heatmap with the mask and correct aspect ratio\n",
    "    snsplot = sns.heatmap(corr, mask=mask, cmap=cmap, center=0,\n",
    "                square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "    \n",
    "    snsplot.figure.savefig(output_file_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A final remark about song year. Most of them are in fact 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_stage2[df_stage2.year == 0].year.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's remove them for the correlation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_corr(df_stage2[df_stage2.year != 0][df_stage2.columns[0:-17]], \"../datastory/figures/correlationComplete.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What do we see here ?\n",
    "\n",
    "1) the value between spotify and MSD on the duration is highly correlated, same for loudness and key, so let's keep the original one \n",
    "\n",
    "2) track_popularity and song_hotttnesss is moderately correlated, thus we will keep the song_hotttnesss\n",
    "\n",
    "3) year of MSD and album release from spotify is absolutely not correlated, so let's keep the one from MSD again\n",
    "\n",
    "4) The acousticness has negative correlation with loudness and energy (which seems logical, as classical music is generally not loud or energetic)\n",
    "\n",
    "5) no feature looks highly, even moderately, correlated to the song_hotttnesss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop the useless columns again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_stage3 = df_stage2.drop(['album_release', 'track_popularity', 'duration_ms', 'key_y', 'loudness_y', 'tempo_x'], axis=1)\n",
    "df_stage3.rename(columns={'key_x': 'key', 'loudness_x': 'loudness', 'tempo_y': 'tempo'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr(df_stage3[df_stage3.year != 0][df_stage3.columns[0:-17]], \"../datastory/figures/correlationReduce.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's do the same thing for genre only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_corr(pd.concat([df_stage3[['song_hotttnesss']],df_stage3[df_stage3.columns[-17:]]], axis=1), \"../datastory/figures/correlationGenre.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want know to check if we can train a regressor and export the features importance. Here we use an RandomForest like in HW4, but a regressor one this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.externals import joblib\n",
    "COMPUTE = True\n",
    "\n",
    "if COMPUTE:\n",
    "    \n",
    "    regressor = RandomForestRegressor(n_jobs=-1, n_estimators = 400, verbose=True)\n",
    "\n",
    "    df_stage4 = df_stage3.copy()\n",
    "    df_stage4 = df_stage4.dropna(axis=0, how='any')\n",
    "    df_stage4 = df_stage4[df_stage4.year > 0]\n",
    "    df_stage4['nb_genre'] = np.sum(df_stage4.iloc[:, -17:].values, axis=1)  \n",
    "    df_stage4 = df_stage4[df_stage4.nb_genre > 0].drop(['nb_genre'], axis=1)\n",
    "    \n",
    "    train_set = df_stage4.drop(['song_hotttnesss'], axis=1)  \n",
    "\n",
    "    train_label = df_stage4.song_hotttnesss\n",
    "\n",
    "    regressor.fit(train_set, train_label)\n",
    "    \n",
    "    #joblib.dump(regressor, 'completeRegressor.pkl')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    regressor = joblib.load('completeRegressor.pkl') \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the importance per feature, in order to extract some useful insights. \n",
    "\n",
    "Note that we sum the importance of each genre to see what they mean for the whole random forest, as we can sum feature to get the importance of a bag of feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genre_sum = 0.0\n",
    "for a, b in sorted(zip(regressor.feature_importances_, train_set.columns), reverse=True):\n",
    "    print(a, \" : \", b)\n",
    "    if b in genres:\n",
    "        genre_sum += a\n",
    "        \n",
    "genre_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that, with a sum of 0.07, the bagging of the genres has the same importance as the others.\n",
    "\n",
    "It looks like we have some really interesting features, but let's create a graph to visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance_df = pd.DataFrame({'label': train_set.columns, 'feature_importance' : regressor.feature_importances_})\n",
    "feature_importance_df = feature_importance_df.sort_values('feature_importance', ascending=False).iloc[:13]\n",
    "feature_importance_df.iloc[12] = [genre_sum, 'genre']\n",
    "\n",
    "order = np.flipud(feature_importance_df.sort_values(by='feature_importance').label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(font_scale=2)\n",
    "fig, ax = plt.subplots(figsize=(20,20))\n",
    "\n",
    "snsplot = sns.barplot(x='feature_importance', y='label', data=feature_importance_df, palette=\"Blues_d\", order=order)\n",
    "\n",
    "snsplot.figure.savefig(\"../datastory/figures/RandomForest_feature_importance.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_scatter(df, y_name, x_name):\n",
    "    sns_plot = sns.lmplot(x=x_name, y=y_name, scatter_kws={\"s\": 2}, line_kws={'color': 'red'}, data=df)\n",
    "    sns_plot.savefig(\"figures/scatter_feature/scatter_\" + x_name + \".png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_with_correct_feature = df_stage3.dropna(axis=0, how='any').copy()\n",
    "\n",
    "df_with_correct_year = df_stage3[df_stage3.year > 0].copy()\n",
    "\n",
    "df_with_correct_genre = df_stage3.copy()\n",
    "df_with_correct_genre['nb_genre'] = np.sum(df_with_correct_genre.iloc[:, -17:].values, axis=1)  \n",
    "df_with_correct_genre = df_with_correct_genre[df_with_correct_genre.nb_genre > 0].drop(['nb_genre'], axis=1)\n",
    "   \n",
    "print(\"correct feature len: \", len(df_with_correct_feature))\n",
    "print(\"correct year len: \", len(df_with_correct_year))\n",
    "print(\"correct genre len: \", len(df_with_correct_genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for feature in df_with_correct_feature.columns[:-17]:\n",
    "    if feature != \"year\" and feature != \"song_hotttnesss\":\n",
    "        plot_scatter(df_with_correct_feature, \"song_hotttnesss\", feature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_scatter(df_with_correct_year, \"song_hotttnesss\", \"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
