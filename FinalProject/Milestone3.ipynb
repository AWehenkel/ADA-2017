{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Acquisition and Cleaning\n",
    "The first part of the document presents the work done in order to obtain a usable dataset. Indeed, the Million Song Dataset (MSD) was lackluster regarding song features (danceability, energy, etc), which were all set to 0. That's why we decided to take additional steps to improve this dataset.    \n",
    "In the first part, we import data from the MSD and we decide to keep only some values of interest from this dataset. Next, we query the Spotify API in order to obtain additional information about each song. In the meantime, we also add genre classification for each song from 3 datasets built around the MSD. Finally, we generate a csv which will be our main resource of data for the rest of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sqlite3\n",
    "from sqlite3 import Error\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import widgets, interactive\n",
    "%matplotlib inline\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sns.set(font_scale=1.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function aims at creating a connection to an SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_connection(db_file):\n",
    "    \"\"\" create a database connection to the SQLite database\n",
    "        specified by the db_file\n",
    "    :param db_file: database file\n",
    "    :return: Connection object or None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        conn = sqlite3.connect(db_file)\n",
    "        return conn\n",
    "    except Error as e:\n",
    "        print(e)\n",
    "\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a quick look at the columns we have at our disposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "database = \"data/track_metadata.db\"\n",
    "conn = create_connection(database)\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"PRAGMA table_info(songs)\")\n",
    "rows = cur.fetchall()\n",
    "print(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Request the dataset and put the data in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cur.execute(\"SELECT track_id, song_id, artist_id, duration, artist_hotttnesss, year FROM songs ORDER BY track_id\")\n",
    "rows = cur.fetchall()\n",
    "songs = pd.DataFrame(rows, columns=['track_id', 'song_id', 'artist_id', 'duration', 'artist_hotttnesss', 'year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 3 following cells merge our data from genres classification coming from 3 datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_genre_cd1 = pd.read_csv('data/msd_tagtraum_cd1.cls', sep='\\t', names=['track_id', 'genre1_cd1', 'genre2_cd1'])\n",
    "songs = track_genre_cd1.merge(songs, on='track_id', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_genre_cd1 = pd.read_csv('data/msd_tagtraum_cd2.cls', sep='\\t', names=['track_id', 'genre1_cd2', 'genre2_cd2'])\n",
    "songs = track_genre_cd1.merge(songs, on='track_id', how='right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "track_genre_cd1 = pd.read_csv('data/msd_tagtraum_cd2c.cls', sep='\\t', names=['track_id', 'genre1_cd2c', 'genre2_cd2c'])\n",
    "songs = track_genre_cd1.merge(songs, on='track_id', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take a look at the analysis of the songs from the MSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msd_summary_file = pd.HDFStore(\"data/msd_summary_file.h5\")\n",
    "songs_analysis = msd_summary_file.get('/analysis/songs')\n",
    "songs_analysis.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And add the data we find interesting. Indeed a lot of columns in this dataset are empty and cannot be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_analysis = songs_analysis[['track_id', 'loudness', 'mode', 'tempo', 'key']]\n",
    "songs = songs_analysis.merge(songs, on='track_id')\n",
    "del(songs_analysis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do the same operation for the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_metadata = msd_summary_file.get('/metadata/songs')\n",
    "songs_metadata.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs_metadata = songs_metadata[['song_hotttnesss', 'song_id', 'artist_latitude', 'artist_location', 'artist_longitude']]\n",
    "songs = songs_metadata.merge(songs, on='song_id')\n",
    "del(songs_metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we take a look at the data we have gathered until now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "songs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to gather data from the Spotify API we have some scripts in auxiliary files (stored in the folder spotify_requests_tools). Using these tools, we created two csv 'feature_songs.csv' and 'track_year_popularity.csv' which contain additional information for each song."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_data = pd.read_csv('data/feature_songs.csv')\n",
    "spotify_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the unknown values(zeros) by NaN\n",
    "for column in spotify_data.columns:\n",
    "    spotify_data.loc[spotify_data[column] == 0, column] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2 = songs.merge(spotify_data, how='left', on='song_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again taking a look at the data we have until now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "songs2.iloc[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_year_pop = pd.read_csv('data/track_year_popularity.csv')\n",
    "final_merge = songs2.merge(spotify_year_pop.drop_duplicates(['song_id'], keep='last'), how='left', on='song_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we take a look at our data and save them into a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge.to_csv('final_merge.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that we have gained some rows while joining the datasets. This may be due to duplicate IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_merge.loc[2,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Year analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_merge.copy()\n",
    "df['album_release'] = df['album_release'].fillna(0).astype(int) #must fill nan with value to convert to int\n",
    "df = df.loc[df['year'] != 0] #don't take 0, as it means unknown\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we still have more than 500k tracks to do our year/time analysis, which should be enough to see correlations if there are any."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df.copy()\n",
    "\n",
    "year_plot = df_c.groupby('year').size().plot(kind='bar', figsize=(16,12), color='g')\n",
    "ax = plt.gca()\n",
    "for label in ax.get_xticklabels(): #Little trick to avoid cluttering the x axis and only see every 5 years\n",
    "    label.set_visible(False)\n",
    "for label in ax.get_xticklabels()[2::5]:\n",
    "    label.set_visible(True)\n",
    "ax.set_ylabel(\"Number of samples\")\n",
    "fig = plt.gcf()\n",
    "fig.suptitle(\"Samples per year\", y=0.9)\n",
    "fig.savefig(\"../year_analysis_plots/samples_per_year.png\", bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "We can see, as expected, that the dataset doesn't have many songs before ~1990. It also stops after 2010 (when the dataset got created). The set is therefore not sampled uniformly on the release date. Indeed, as explained on the MSD website, the dataset was chosen using the most popular artist / tracks, which explains why older songs are underrepresented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_by(df, idx, column, ax=None):\n",
    "    '''\n",
    "        Plot a column (y axis) against an index (x axis)\n",
    "        Will generate a plot matching for each idx value the mean of the column value for this idx.\n",
    "        :param df: The dataframe containing the data\n",
    "        :param idx: The x axis series\n",
    "        :param column: the y axis series\n",
    "        :param ax: A custom axis object to plot on\n",
    "        :type df: DataFrame\n",
    "        :type idx: string\n",
    "        :type column: string\n",
    "        :type ax: Axes\n",
    "    '''\n",
    "    df_c = df.copy()\n",
    "    df_c = df_c[[idx,column]]\n",
    "    if ax == None:\n",
    "        axes = plt.gca()\n",
    "    else:\n",
    "        axes = ax\n",
    "    axes.set_xlabel(idx)\n",
    "    axes.set_ylabel(column)\n",
    "    df_c.groupby([idx]).mean().plot(ax=ax)\n",
    "    \n",
    "def plot_by_year(df, column, ax = None):\n",
    "    '''\n",
    "        Plot a column (y axis) against the year (x axis)\n",
    "        Will generate a plot matching for each year the mean of the column value for this year.\n",
    "        :param df: The dataframe containing the data\n",
    "        :param column: the y axis series\n",
    "        :param ax: A custom axis object to plot on\n",
    "        :type df: DataFrame\n",
    "        :type column: string\n",
    "        :type ax: Axes\n",
    "    '''\n",
    "    plot_by(df,'year',column, ax=ax)\n",
    "    \n",
    "def plot_heatmap_by(df, idx, column, ax = None):\n",
    "    '''\n",
    "        Plot a heatmap using an index (x axis), and a column (y axis)\n",
    "        The color value of the heatmap will be the number of samples for this coordinate.\n",
    "        :param df: The dataframe containing the data\n",
    "        :param idx: the name of the x axis series\n",
    "        :param column: the name of the y axis series\n",
    "        :param ax: A custom axis object to plot on\n",
    "        :type df: DataFrame\n",
    "        :type idx: string\n",
    "        :type column: string\n",
    "        :type ax: Axes\n",
    "    '''\n",
    "    df_c = df.copy()\n",
    "    df_c = df_c[[idx,column]]\n",
    "    if df[column].dtype == np.float or df[column].dtype == np.float64: #Bin the data if needed\n",
    "        bins = np.linspace(df[column].min(),df[column].max(),20)\n",
    "        df_c[column] = pd.cut(df_c[column],bins)\n",
    "    df_c = df_c.dropna()\n",
    "    df_count = pd.DataFrame(df_c.groupby([idx, column]).size().rename('count'))\n",
    "    df_c = df_c.join(df_count, on=[idx,column])\n",
    "    df_c = df_c.reset_index().pivot_table(index=idx, columns=column, values='count', aggfunc='mean')\n",
    "    if ax==None:\n",
    "        axes = plt.gca()\n",
    "    else:\n",
    "        axes = ax\n",
    "    axes.set_xlabel(idx)\n",
    "    axes.set_ylabel(column)\n",
    "    sns.heatmap(df_c, ax=ax, cbar_kws={'label': 'Number of samples'})\n",
    "\n",
    "def plot_heatmap_by_year(df, column, ax=None):\n",
    "    '''\n",
    "        Plot a heatmap using a column (y axis) against the years\n",
    "        The color value of the heatmap will be the number of samples for this coordinate.\n",
    "        :param df: The dataframe containing the data\n",
    "        :param column: the name of the y axis series\n",
    "        :param ax: A custom axis object to plot on\n",
    "        :type df: DataFrame\n",
    "        :type column: string\n",
    "        :type ax: Axes\n",
    "    '''\n",
    "    plot_heatmap_by(df, 'year', column, ax=ax)\n",
    "    \n",
    "def plot_for_year(df, column, year, ax=None, decade=False):\n",
    "    '''\n",
    "        Plot a stripplot (lineplot) of a feature / column for a given year against the song_hotttnesss\n",
    "        The plot will have jitter to better visualize the data\n",
    "        :param df: The dataframe containing the data\n",
    "        :param column: the name of the series\n",
    "        :param year: the year\n",
    "        :param ax: A custom axis object to plot on\n",
    "        :param decade: Whether to consider the whole decade or not\n",
    "        :type df: DataFrame\n",
    "        :type column: string\n",
    "        :type year: int\n",
    "        :type ax: Axes\n",
    "        :type decade: boolean\n",
    "    '''\n",
    "    df_c = df.copy()\n",
    "    if decade:\n",
    "        df_c['year'], bins=pd.cut(df_c['year'],range(1960,2020,10), include_lowest=True, retbins=True)\n",
    "        interval = pd.Interval(year, year+10)\n",
    "        df_c = df_c[interval==df_c['year']]\n",
    "    else:\n",
    "        df_c = df_c[df_c['year']==year]\n",
    "    df_c = df_c[[column, 'song_hotttnesss']]\n",
    "    df_c['song_hotttnesss'], bins = pd.cut(df_c['song_hotttnesss'],np.linspace(0,1,11), retbins=True) #Bin the song hotness\n",
    "    if ax == None:\n",
    "        axes = plt.gca()\n",
    "    else:\n",
    "        axes = ax\n",
    "\n",
    "    axes.set_xlim(df[column].min()-0.1,df[column].max()+0.1)\n",
    "    axes.set_xlabel(column)\n",
    "    axes.set_ylabel(year)\n",
    "    sns.stripplot(x=column, y='song_hotttnesss',data=df_c, jitter=0.5, ax=axes)\n",
    "    axes.invert_yaxis()\n",
    "    min_y = axes.get_ylim()[0]\n",
    "    max_y = axes.get_ylim()[1]\n",
    "    length = max_y-min_y\n",
    "    for hotness in df_c['song_hotttnesss'].unique(): #Plot the mean of each song hotness bin\n",
    "        if type(hotness)==pd.Interval:\n",
    "            median = df_c.loc[df_c['song_hotttnesss']==hotness][column].median()\n",
    "            start = hotness.left\n",
    "            end = hotness.right\n",
    "            axes.plot([median,median], [length*start+min_y, length*end+min_y], color='k', zorder=1000)\n",
    "    \n",
    "    \n",
    "def plot_heatmap_for_year(df, column1, column2, year, ax=None):\n",
    "    '''\n",
    "        Plot a kdeplot of two features / columns for a given year\n",
    "        It will allow to see correlation between the two columns\n",
    "        :param df: The dataframe containing the data\n",
    "        :param column1: the name of the first series\n",
    "        :param column2: the name of the second series\n",
    "        :param year: the year\n",
    "        :param ax: A custom axis object to plot on\n",
    "        :type df: DataFrame\n",
    "        :type column1: string\n",
    "        :type column2: string\n",
    "        :type year: int\n",
    "        :type ax: Axes\n",
    "    '''\n",
    "    df_c = df.copy()\n",
    "    df_c = df_c[df_c['year']==year]\n",
    "    df_c = df_c[[column1, column2]]\n",
    "    df_c = df_c.dropna()\n",
    "    if ax == None:\n",
    "        axes = plt.gca()\n",
    "    else:\n",
    "        axes = ax\n",
    "    axes.set_xlabel(column1)\n",
    "    axes.set_ylabel(column2)\n",
    "    sns.kdeplot(df_c[column1], df_c[column2], cmap=\"Reds\", shade=True, shade_lowest=False, ax=axes)\n",
    "\n",
    "def ceil(x):\n",
    "    '''\n",
    "        Shortcut for np.ceil(x).astype(int)\n",
    "        :param x: the value to ceil\n",
    "        :type x: number\n",
    "        :return: The result of the ceiling as an int\n",
    "        :rtype: int\n",
    "    '''\n",
    "    return np.ceil(x).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We select the features which make sense and then plot their evolution through the years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = ['song_hotttnesss', 'loudness_x', 'mode_x', 'tempo_x', 'key_x', 'duration', 'artist_hotttnesss', 'danceability', 'energy', 'key_y', 'loudness_y', 'mode_y', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo_y', 'duration_ms']\n",
    "selected.sort()\n",
    "\n",
    "n_cols = 4\n",
    "n_rows = ceil(len(selected)/n_cols)\n",
    "fig, ax = plt.subplots(n_rows,n_cols)\n",
    "fig.set_size_inches(20,n_rows*20/n_cols)\n",
    "idx_r = 0\n",
    "idx_c = 0\n",
    "\n",
    "#For each feature, plot the mean of the feature for each year\n",
    "for col in selected:\n",
    "    plot_by_year(df,col,ax=ax[idx_r, idx_c])\n",
    "    if idx_c==n_cols-1:\n",
    "        idx_r+=1\n",
    "        idx_c=0\n",
    "    else:\n",
    "        idx_c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "\n",
    "For most of the data before ~1960, there is a huge variance due to the low number of samples. However, we can still see tendencies for several features.    \n",
    "- Duration : We can see a clear spike (for both duration and duration_ms) around 1960. We suppose that it is due to the apparition and democratization of the vinyl record (more precisely its more modern iteration). This allowed the musicians to store longer musics (which seemed to be a problem before). However, the duration hasn't increased since, probably because the artists and public feel that the current mean duration is the most optimal one.\n",
    "\n",
    "- Acousticness : We see a massive drop through the years. This is surely due to the apparition of the electronic music (acousticness is determined by the absence of electronic instruments).\n",
    "\n",
    "- Loudness : The music seems to get louder and louder. This is probably due to cultural changes (genre, etc).\n",
    "\n",
    "- Energy : The energy also increases along with the loudness.\n",
    "\n",
    "- Song hotness : The hotness seems to spike at around 2010. This may be explained by the algorithm, if it is similar to the one of Spotify, the hotness is hugely influenced by the recency of the music, which explains this result. Otherwise, this may be due to the same problem seen with tempo, mode, etc, which all spike at the end of the graph.\n",
    "\n",
    "- We can drop mode_y, as it is always 1.\n",
    "\n",
    "- We can't really say much about the other values, except that they seem to stay stable through the years."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = 1\n",
    "selected = ['song_hotttnesss', 'loudness_x', 'mode_x', 'tempo_x', 'key_x', 'duration', 'artist_hotttnesss', 'danceability', 'energy', 'key_y', 'loudness_y', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo_y', 'duration_ms']\n",
    "n_rows = ceil(len(selected)/n_cols)\n",
    "fig, ax = plt.subplots(n_rows,n_cols)\n",
    "fig.set_size_inches(20,n_rows*20/n_cols/2) #Trying to find a good aspect\n",
    "fig.tight_layout()\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "\n",
    "#For each feature, print the heatmap of the feature regarding the year\n",
    "for idx,col in enumerate(selected):\n",
    "    plot_heatmap_by_year(df, col, ax=ax[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "These graphs don't show much, except that most of the samples are recent, as seen earlier (and what feature values those recent years samples have). We could perhaps normalize by year to have a better visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = 2\n",
    "year_r = range(1960,2012)\n",
    "n_rows = np.ceil(len(year_r)/n_cols).astype(int)\n",
    "fig, ax = plt.subplots(n_rows,n_cols)\n",
    "fig.set_size_inches(20,n_rows/n_cols*20)\n",
    "idx_r = 0\n",
    "idx_c = 0\n",
    "\n",
    "#Plot the song hotness distribution for each year\n",
    "for year in year_r:\n",
    "    plot_for_year(df,'song_hotttnesss',year,ax=ax[idx_r, idx_c])\n",
    "    if idx_c==n_cols-1:\n",
    "        idx_r+=1\n",
    "        idx_c=0\n",
    "    else:\n",
    "        idx_c+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis example\n",
    "\n",
    "The first thing we remark is that a lot of the samples have an hotness of 0. We wondered if this means that the song hasn't been rated, but the description of the dataset just says that the hotness goes from 0 to 1, thus it seems that those songs are just really unpopular (which seems plausible).\n",
    "\n",
    "We can see that, although the number of samples drastically increases as time goes on, the distribution roughly stays the same (which we could see in the previous graphs). We can also distinguish what looks like lines around 0.2, 0.27, 0.3 mainly (which means an higher concentration of samples). We don't know if it is due to the algorithm used for the rating or if this is just a coincidence at the moment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You will need the ipython extensions / widgets enabled to use the interactive graph below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df.copy()\n",
    "df_c = df_c[df_c['year']>=1960] #Only take after 1960, as before there are very few samples\n",
    "DECADE = \"Decade\"\n",
    "SINGLE_YEAR = \"Single year\"\n",
    "df_c['artist_hotttnesss'][df_c['artist_hotttnesss']<0]=0 # Clamp the artist hotness as the data is sometimes faulty\n",
    "df_c['artist_hotttnesss'][df_c['artist_hotttnesss']>1]=1\n",
    "decades = widgets.RadioButtons( #Button to select year or decade\n",
    "options=[DECADE,SINGLE_YEAR],value=SINGLE_YEAR, disabled=False, description=\"Year grouping\")\n",
    "year = widgets.BoundedIntText( #Field to select year\n",
    "    value=1960,\n",
    "    min=1960,\n",
    "    max=2010,\n",
    "    step=1,\n",
    "    description='Year:',\n",
    "    disabled=False,\n",
    "    color='black'\n",
    ")\n",
    "def update_year(*args):\n",
    "    \"\"\"\n",
    "    Update the year widget depending on the button value\n",
    "    \"\"\"\n",
    "    if decades.value==SINGLE_YEAR:\n",
    "        year.step=1\n",
    "        year.max=2010\n",
    "        year.description='Year:'\n",
    "    else:\n",
    "        year.step=10\n",
    "        year.value=np.round(year.value/10)*10\n",
    "        year.max=2000\n",
    "        year.description=\"Decade:\"\n",
    "    \n",
    "decades.observe(update_year,'value') #Listener\n",
    "\n",
    "feature = widgets.Dropdown( #Widget to select the feature\n",
    "    options=selected[1:], #Don't take song hotness\n",
    "    value='loudness_x',\n",
    "    description='Feature:',\n",
    ")\n",
    "\n",
    "def save_all_plots():\n",
    "    \"\"\"\n",
    "    Saves all the year stripplots\n",
    "    \"\"\"\n",
    "    for f in selected[1:]:\n",
    "        for year in range(1960, 2011):\n",
    "            plotit(f, year, SINGLE_YEAR)\n",
    "            fig = plt.gcf()\n",
    "            fig.savefig(\"../year_analysis_plots/single_year/\"+f+\"_\"+str(year)+\".png\", bbox_inches='tight')\n",
    "            if year<2010 and year%10==0: #Save the decades too\n",
    "                plotit(f,year,DECADE)\n",
    "                fig = plt.gcf()\n",
    "                fig.savefig(\"../year_analysis_plots/decade/\"+f+\"_\"+str(year)+\"-\"+str(year+10)+\".png\",bbox_inches=\"tight\")\n",
    "            \n",
    "def plotit(feature, year, decades):\n",
    "    df_d = df_c.copy()\n",
    "    plt.clf()\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(16,16)\n",
    "    decade = decades==DECADE\n",
    "    ax = plt.gca()\n",
    "    if decade:\n",
    "        title = str(year)+\" - \"+str(year+10)\n",
    "    else:\n",
    "        title = str(year)\n",
    "    fig.suptitle(title, y=0.9)\n",
    "    plot_for_year(df_d,feature,year, decade=decade)\n",
    "\n",
    "interactive(plotit,feature=feature, year=year, decades = decades)\n",
    "# save_all_plots()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "The analysis will be done by decade, as otherwise the values per year jump a lot, and grouping by decade helps to visualize better the evolution of the features (their tendency). To avoid cluttering the notebook, the plots have been saved and examined on the disk (they are also available on the github repository).\n",
    "\n",
    "### Features\n",
    "First off, the features don't seem to influence the song hotness at all (except for the artist hotness obviously), which is a bit of a letdown. The median for each song hotness bin seems to be around the same value, and the distributions the same.\n",
    "\n",
    "### Evolution\n",
    "There are some evolutions through the years / decades though:\n",
    "- The acousticness seems to decrease throughout the years, and the mean acousticness is quite low overall.\n",
    "- The duration increased from the 60s to the 70s, and then stayed at ~250s.\n",
    "- The songs become more and more energetic decade after decade.\n",
    "- The loudness also increases with the decades. The top songs seems to be louder as well.\n",
    "- The valence decreases with the time, and the top songs hang around 0.5 valence."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "We can't really see any link between a feature through the years and the song hotness. We also can't, for most of the features, see any real evolution. These problems are maybe due to the selection bias of the MSD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_merge.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.columns.values[0] = 'id'\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df[(pd.isnull(df.genre1_cd1) == False) | (pd.isnull(df.genre1_cd2) == False) | (pd.isnull(df.genre1_cd2c) == False)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_year = df2.groupby(['year']).size().reset_index(name='counts')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we check the number of song per year we have in the dataset. As expected we see an increase in the number of songs over the year except for 2010, this is probably because the year 2010 was just ending when the dataset was created and the 2010 songs hadn't had the time to attain their maximum popularity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_year.iloc[1:, :].plot(x='year', y='counts', kind='line')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said before there are not a lot of songs before the 60s, thus we will drop this song to continues a meaningful analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2[df2.year > 1960]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = set([])\n",
    "genres_cols = ['genre1_cd2c', 'genre2_cd2c', 'genre1_cd2', 'genre2_cd2', 'genre1_cd1', 'genre2_cd1']\n",
    "for col_name in genres_cols:\n",
    "    genres = genres | set(df2[col_name].unique())\n",
    "print(genres)\n",
    "print(len(genres))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have 17 different genres (nan are unkown and international is the same as world). To do a meaningful analysis of the genre analysis over the year a minimum amount of songs of the analyzed type must be in the dataset. In the following cells we first replace the nan and replace International by World. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[genres_cols] = df2[genres_cols].fillna('Unknown')\n",
    "df2[genres_cols] = df2[genres_cols].replace('International', 'World')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genres = set([])\n",
    "genres_cols = ['genre1_cd2c', 'genre2_cd2c', 'genre1_cd2', 'genre2_cd2', 'genre1_cd1', 'genre2_cd1']\n",
    "for col_name in genres_cols:\n",
    "    genres = genres | set(df2[col_name].unique())\n",
    "    df2[col_name] = df2[col_name].astype(str)\n",
    "print(genres)\n",
    "print(len(genres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[genres_cols].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the moment we have 6 columns for the genres, we would like to see if we can summarize these columns in one or two columns.\n",
    "First we perform a pivot and count the number of different values present in each column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in list(genres):\n",
    "    df2[genre] = 0\n",
    "    for col_name in genres_cols:\n",
    "        df2.loc[df2[col_name] == genre, genre] = 1\n",
    "df2 = df2.drop(columns=['Unknown'])\n",
    "genres.remove('Unknown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['nb_genre'] = np.sum(df2.iloc[:, -17:].values, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['nb_genre'].plot(kind='hist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we see that the majority of the songs have 1 or 2 different genres, some also have 3 genres and 4 genres is atypical. We can now drop the 6 columns containing the label genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df2.drop(columns=genres_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for each genre we plot the number of samples per year."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "int(len(list(genres))/3.0 + .5)\n",
    "f, axarr = plt.subplots(int(len(list(genres))/3.0 + .5), 3)\n",
    "f.set_size_inches(15, 20)\n",
    "plt.subplots_adjust(hspace=.4)\n",
    "i = 0\n",
    "all_data = {}\n",
    "for genre in genres:\n",
    "    data_genre = df2[df2[genre] == 1].groupby(['year']).size().reset_index(name='counts')\n",
    "    data_genre.plot(x='year', y='counts', kind='line', title=genre, ax=axarr[int(i/3), i%3])\n",
    "    fig = axarr[int(i/3), i%3].get_figure()\n",
    "    extent = axarr[int(i/3), i%3].get_window_extent().transformed(fig.dpi_scale_trans.inverted())\n",
    "    data = {}\n",
    "    data['years'] = list(data_genre['year'].astype(str).values)\n",
    "    data['count'] = list(data_genre['counts'].values)\n",
    "    all_data[genre] = data\n",
    "    #fig.savefig('figures/%s_distri_year.png' % (genre), bbox_inches=extent.expanded(1.2, 1.15), dpi = 500)\n",
    "    i+=1\n",
    "f = open('counts.json','w')\n",
    "f.write(str(all_data))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These plots are useful to see the data we have in our hands. \n",
    "\n",
    "Firstly we observe that most of the music we have is rock, pop, pop_rock, electronic or metal. On the opposite World, Latin, blues are not very represented. This can be explained either because the dataset is biased or also because some genres are more popular. Indeed Latin music is sub-represented although there is a very important latin culture in the world. These observations could be made more precise by using only the total number of songs for each genre.\n",
    "\n",
    "Secondly these plots allow us to see some trends in the evolution of the music. If we suppose the dataset is not too much biased for the genre the most represented, we can make some interesting observations. We can see that punk music suddenly appears in the middle of the 70's. Rock started in the 60's and grows exponentially since this moment. Indeed these plots are useful to tell something about when the genre appears and how it has evolved since this moment. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to look how genres are connected, so let's construct a graph in which nodes are the genre and a connection between two genres appears when a song has both genres. The weight of the connection is given by the number of songs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_mat_genres = np.zeros([len(genres), len(genres)])\n",
    "genres = list(genres)\n",
    "for i in range(len(genres)):\n",
    "    for j in range(i, len(genres)):\n",
    "        nb_songs = df2[(df2[genres[i]] == 1) & (df2[genres[j]] == 1)].shape[0]\n",
    "        adj_mat_genres[i, j] = nb_songs\n",
    "        adj_mat_genres[j, i] = nb_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "adj_mat_genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_df = pd.DataFrame(adj_mat_genres, columns=genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_df['genre'] = genres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_df['radius'] = (np.diag(adj_mat_genres))**.5\n",
    "adj_df['id'] = range(len(adj_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_df[['radius', 'id', 'genre']].T.to_dict().values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "a = adj_df[['radius', 'id', 'genre']].T.to_dict().values()\n",
    "list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj_df = adj_df.iloc[:, :-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "adj = adj_df.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edges = []\n",
    "for i in range(len(adj)):\n",
    "    for j in range(i+1, len(adj)):\n",
    "        edge = {'source_id': i, 'target_id': j, 'stroke_width': adj[i, j]/1000}\n",
    "        edges.append(edge)\n",
    "edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<iframe src=\"http://www.cbinge.com/file/test.html\" width=1000 height = 1000/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "int(len(list(genres))/3.0 + .5)\n",
    "f, axarr = plt.subplots(int(len(list(genres))/3.0 + .5), 3)\n",
    "f.set_size_inches(15, 20)\n",
    "plt.subplots_adjust(hspace=.4)\n",
    "i = 0\n",
    "all_data = {}\n",
    "\n",
    "# Compute the avg hotness by year for all the data\n",
    "hottness_avg = df2[df2['song_hotttnesss'].notna()].groupby(['year']).mean().reset_index()\n",
    "regr = RandomForestRegressor(n_estimators=10, n_jobs=-1, max_depth= 5)\n",
    "regr.fit(hottness_avg[['year']], hottness_avg['song_hotttnesss'])\n",
    "hottness_predict = regr.predict(np.array(list(range(1960, 2011))).reshape(-1, 1))\n",
    "data = {}\n",
    "data['years'] = list(hottness_avg['year'].astype(str).values)\n",
    "data['hottness'] = list(hottness_avg['song_hotttnesss'].values)\n",
    "data['predict'] = list(hottness_predict)\n",
    "all_data['avg'] = data\n",
    "\n",
    "# Compute it for each genre\n",
    "for genre in genres:\n",
    "    regr = RandomForestRegressor(n_estimators=10, n_jobs=-1, max_depth= 5)\n",
    "    hottness = df2[(df2[genre] == 1) & df2['song_hotttnesss'].notna()].groupby(['year']).mean().reset_index()\n",
    "    hottness = hottness[hottness['song_hotttnesss'] > 0]\n",
    "    regr.fit(hottness[['year']], hottness['song_hotttnesss'])\n",
    "    hottness.plot(x='year', y='song_hotttnesss', kind='scatter', title=genre, ax=axarr[int(i/3), i%3], color='orange')\n",
    "    hottness_predict = regr.predict(np.array(list(range(1960, 2011))).reshape(-1, 1))\n",
    "    axarr[int(i/3), i%3].plot(list(range(1960, 2011)), hottness_predict)\n",
    "    data = {}\n",
    "    data['years'] = list(hottness['year'].astype(str).values)\n",
    "    data['hottness'] = list(hottness['song_hotttnesss'].values)\n",
    "    data['predict'] = list(hottness_predict)\n",
    "    all_data[genre] = data\n",
    "    i+=1\n",
    "f = open('hottness.json','w')\n",
    "f.write(str(all_data))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Milestone 3\n",
    "### Analysis of the distribution of the different features for each genre\n",
    "Look at the empirical probability function of the genre.\n",
    "### Look at the influence of the year of these distribution\n",
    "Is genre time invariant or not?\n",
    "### Visualize the interesting results obtained\n",
    "Visualization by using graph evolving with time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for genre in genres:\n",
    "    tmp = df2[df2[genre] == 1].reset_index()\n",
    "    text = tmp[['song_hotttnesss', 'duration', 'speechiness', 'acousticness', 'instrumentalness']].describe().to_html()\n",
    "    f = open('figures/%s.tab'%genre,'w')\n",
    "    f.write(text)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "for col in ['song_hotttnesss', 'duration', 'speechiness', 'acousticness', 'instrumentalness']:\n",
    "    all_data = {}\n",
    "\n",
    "    # Compute the avg hotness by year for all the data\n",
    "    avg = df2[df2[col].notna()].groupby(['year']).mean().reset_index()\n",
    "    regr = RandomForestRegressor(n_estimators=10, n_jobs=-1, max_depth= 5)\n",
    "    regr.fit(hottness_avg[['year']], avg[col])\n",
    "    predict = regr.predict(avg['year'].values.reshape(-1, 1))\n",
    "    data = {}\n",
    "    data['years'] = list(avg['year'].astype(str).values)\n",
    "    data[col] = list(avg[col].values)\n",
    "    data['predict'] = list(predict)\n",
    "    all_data['avg'] = data\n",
    "\n",
    "    # Compute it for each genre\n",
    "    print(\"%s: \" % col)\n",
    "    for genre in genres:\n",
    "        regr = RandomForestRegressor(n_estimators=10, n_jobs=-1, max_depth= 5)\n",
    "        datas = df2[(df2[genre] == 1) & df2[col].notna()]\n",
    "        col_data = datas.groupby(['year']).mean().reset_index()\n",
    "        col_data = col_data[col_data[col] > 0]\n",
    "        regr.fit(col_data[['year']], col_data[col])\n",
    "        predict = regr.predict(hottness_avg['year'].values.reshape(-1, 1))\n",
    "        data = {}\n",
    "        data['years'] = list(hottness['year'].astype(str).values)\n",
    "        data[col] = list(col_data[col].values)\n",
    "        data['predict'] = list(predict)\n",
    "        all_data[genre] = data\n",
    "        i+=1\n",
    "        avg += np.mean(col_data[col].values)\n",
    "        print(\"\\t %s: Nb songs = %d and Avg Value is %f\" % (genre, len(datas), np.mean(data[col])))\n",
    "    f = open('%s.json' % col,'w')\n",
    "    f.write(str(all_data))\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df2[df2['speechiness'].notna()])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
