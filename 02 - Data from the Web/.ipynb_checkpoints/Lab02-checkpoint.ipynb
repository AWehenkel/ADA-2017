{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "%pylab inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "\n",
    "Obtain the 200 top-ranking universities in www.topuniversities.com (ranking 2018). In particular, extract the following fields for each university: name, rank, country and region, number of faculty members (international and total) and number of students (international and total). Some information is not available in the main list and you have to find them in the details page. Store the resulting dataset in a pandas DataFrame and answer the following questions:\n",
    "\n",
    "Which are the best universities in term of:       \n",
    "(a) ratio between faculty members and students,     \n",
    "(b) ratio of international students?       \n",
    "Answer the previous question aggregating the data by      \n",
    "(c) country and     \n",
    "(d) region.\n",
    "\n",
    "Plot your data using bar charts and describe briefly what you observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define some variables we will use several times in the code.    \n",
    "We then simply use a request to get the main page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TOP_COUNT = 200\n",
    "fac_members = 'fac_members'\n",
    "inter_fac_members = 'inter_fac_members'\n",
    "students = 'students'\n",
    "inter_students = 'inter_students'\n",
    "ratio_inter_students = 'ratio_inter_students'\n",
    "country = 'country'\n",
    "region = 'region'\n",
    "ratio_fac_students = 'ratio_fac_students'\n",
    "\n",
    "top_uni_json_link = \"https://www.topuniversities.com/sites/default/files/qs-rankings-data/357051.txt?_=1508402735534\"\n",
    "r = requests.get(top_uni_json_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to retrieve the number of students / faculty members given an url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def retrieve_people_number(url):\n",
    "    div = 'div'\n",
    "    data_carousel = 'academic-data-carousel'\n",
    "    complete_url = \"https://www.topuniversities.com/\" + url\n",
    "    r = requests.get(complete_url)\n",
    "    \n",
    "    soup = BeautifulSoup(r.text, 'html.parser') #Parse using BeautifulSoup\n",
    "    \n",
    "    numbers = soup.find(div, {'id':data_carousel})\n",
    "    if (numbers==None): #If we can't find the data, we skip it\n",
    "        print(\"error at : \" + url)\n",
    "        return None\n",
    "    \n",
    "    numbers = numbers.find_all(div, class_='number')\n",
    "    \n",
    "    #We remove the comma in the numbers\n",
    "    numbers = list(map(lambda x: int(x.contents[0].replace('\\n', '').replace(',', '')), numbers)) \n",
    "    if(len(numbers) == 4): \n",
    "        return numbers\n",
    "    else:\n",
    "        #If there isn't enough data, we perform some additional steps\n",
    "        print(\"wrong number of elements at : \" + url)\n",
    "        #We find the h3 tags and find which ones are available\n",
    "        h3s = soup.find(div, {'id':data_carousel}).find_all('h3') \n",
    "        h3s = list(map(lambda x: (x.contents[0].replace('\\n', '').replace(',', '')), h3s))\n",
    "        labels = ['Number of academic faculty staff','International','Number of students','Number of international students']\n",
    "                \n",
    "        result = [np.nan, np.nan, np.nan, np.nan]\n",
    "        for h in range(0, len(h3s)):\n",
    "            idx = labels.index(h3s[h])\n",
    "            result[idx] = numbers[h]\n",
    "        \n",
    "        return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create the DataFrame using the data from the main page, then populate a new DataFrame by iterating in the original DataFrame and retrieving the details for each university"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_uni_df = pd.DataFrame(r.json()['data']).head(TOP_COUNT)\n",
    "\n",
    "missing_datas = pd.DataFrame(columns=[fac_members,inter_fac_members,students,inter_students])\n",
    "for index, row in top_uni_df.iterrows(): \n",
    "    tmp = retrieve_people_number(row.url)\n",
    "    if(tmp != None):\n",
    "        missing_datas.loc[index] = tmp\n",
    "    else: \n",
    "        missing_datas.loc[index] = [np.nan, np.nan, np.nan, np.nan]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then simply concatenate them and calculate the ratio faculty members/students and international students/students. We then drop the columns we won't need anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def agg_by_and_calculate_ratio(df, byS, second):\n",
    "    if (second):\n",
    "        df=df[[byS,fac_members,students,inter_students]].groupby(by=[byS]).agg(sum)\n",
    "    else:\n",
    "        df=df[[byS,fac_members,inter_fac_members,students,inter_students]].groupby(by=[byS]).agg(sum)\n",
    "    return calculate_ratio(df)\n",
    "\n",
    "def calculate_ratio(df):\n",
    "    df[ratio_fac_students] = df[fac_members].values / df[students]\n",
    "    df[ratio_inter_students] = df[inter_students].values / df[students]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_uni_df_complete = pd.concat([top_uni_df, missing_datas], axis=1)\n",
    "top_uni_df_complete.drop(['cc','core_id', 'guide','logo','nid','score','stars','url'], axis=1, inplace=True)\n",
    "\n",
    "calculate_ratio(top_uni_df_complete)\n",
    "\n",
    "top_uni_df_complete.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We expect the USA and UK to have a big ratio of international students. We don't really have expectations for faculty members."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_uni_df_complete.sort_values(ratio_fac_students, ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_uni_df_complete.sort_values(ratio_inter_students, ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our assumption is mostly true, as 3 in the top 5 are universities from UK or USA. Also, EPFL is second place with 57% of international students.\n",
    "\n",
    "We then aggregate by country, and then by region. We recalculate the ratios using the aggregated numbers, instead of doing a mean on the ratios (as that would be false, given that a small university could have a big ratio but shouldn't have a big impact on the total.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_by_and_calculate_ratio(top_uni_df_complete, region, False).sort_values(ratio_inter_students,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, Europe and North America are in top 3, but Oceania is far ahead with 34%, which we didn't expect. That should be mostly due to Australia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "agg_by_and_calculate_ratio(top_uni_df_complete,country,False).sort_values(ratio_inter_students,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, looking at the ratio for international students, Australia is in first place. UK is close second, as expected, but USA is quite far down, which is a surprise. That's probably due to the difficulty to be accepted without an existing deal between an USA university and another. Switzerland is also notably fifth on the list."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "Obtain the 200 top-ranking universities in www.timeshighereducation.com (ranking 2018). Repeat the analysis of the previous point and discuss briefly what you observed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We simply repeat the same process, although we don't have to make other requests to obtain the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stats_student_staff_ratio = 'stats_student_staff_ratio'\n",
    "title_s = 'title'\n",
    "times_high_json_link = \"https://www.timeshighereducation.com/sites/default/files/the_data_rankings/world_university_rankings_2018_limit0_369a9045a203e176392b9fb8f8c1cb2a.json\"\n",
    "r = requests.get(times_high_json_link)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "times_high_df = pd.DataFrame(r.json()['data']).head(TOP_COUNT)\n",
    "\n",
    "times_high_df = times_high_df[['location','aliases','name','rank','stats_number_students','stats_pc_intl_students','stats_student_staff_ratio']]\n",
    "times_high_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_high_df[ratio_inter_students] = times_high_df['stats_pc_intl_students'].str.replace('%','').astype(int) / 100.0\n",
    "times_high_df[stats_student_staff_ratio] = 1.0 / times_high_df[stats_student_staff_ratio].astype(float)\n",
    "times_high_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "times_high_df[students] = times_high_df['stats_number_students'].astype(str).str.replace(',','').astype(int)\n",
    "times_high_df[inter_students] = np.round(times_high_df[students] * times_high_df[ratio_inter_students]).astype(int)\n",
    "times_high_df[fac_members] = np.round(times_high_df[students] * times_high_df[stats_student_staff_ratio]).astype(int)\n",
    "times_high_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We drop some useless columns and rename others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "times_high_df_complete = times_high_df.drop(['stats_pc_intl_students', 'aliases', 'stats_number_students'], axis=1)\n",
    "times_high_df_complete.rename(columns = {stats_student_staff_ratio: ratio_fac_students, 'location': country,'name': title_s}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't have the region in this case, therefore we only group by country. \n",
    "\n",
    "We expect roughly the same results as with the other website, obviously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_by_and_calculate_ratio(times_high_df_complete, country, True).sort_values(ratio_inter_students,ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are indeed somewhat the same (some places are swapped), except for Luxembourg being first. Indeed, Luxembourg wasn't on the first website, which explains why we didn't expect this country being first at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "\n",
    "Merge the two DataFrames created in questions 1 and 2 using university names. Match universities' names as well as you can, and explain your strategy. Keep track of the original position in both rankings.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to 'sanitize' a column and apply it to both dataframes.\n",
    "\n",
    "We make both strings lowercase, remove common accents, translate some words (as a website stores the english name and the other the local name), remove words like \"of, at, the\" and \"de\", remove spaces and quotes.\n",
    "\n",
    "We check by printing the difference of the outer and inner join if there are other patterns which make the names not match, apply it, check again, etc and do it iteratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sanitize_column(c):\n",
    "    return c.str.lower(). \\\n",
    "    str.replace('ä','a'). \\\n",
    "    str.replace('é','e'). \\\n",
    "    str.replace('freie','free'). \\\n",
    "    str.replace('universitat','university'). \\\n",
    "    str.replace('universitaet','university'). \\\n",
    "    str.replace('universidad', 'university'). \\\n",
    "    str.replace('universite','university'). \\\n",
    "    str.replace('technische','technical'). \\\n",
    "    str.replace(r'\\(.*\\)', ''). \\\n",
    "    str.replace('the ',''). \\\n",
    "    str.replace(' of ',''). \\\n",
    "    str.replace(' at ',''). \\\n",
    "    str.replace(' de ',''). \\\n",
    "    str.replace(r',|\\.',''). \\\n",
    "    str.replace(' ',''). \\\n",
    "    str.replace('\\'','’')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_uni_bef_merge = top_uni_df_complete.copy()\n",
    "top_uni_bef_merge[title_s] = sanitize_column(top_uni_bef_merge[title_s])\n",
    "\n",
    "times_high_bef_merge = times_high_df_complete.copy()\n",
    "times_high_bef_merge[title_s] = sanitize_column(times_high_bef_merge[title_s])\n",
    "\n",
    "inner_title_s = top_uni_bef_merge.merge(times_high_bef_merge, on=title_s, how='inner').sort_values(title_s)[title_s]\n",
    "outer_title_s = top_uni_bef_merge.merge(times_high_bef_merge, on=title_s, how='outer').sort_values(title_s)[title_s]\n",
    "list_ = list(set(outer_title_s)-set(inner_title_s))\n",
    "list_.sort()\n",
    "#print(len(list_))\n",
    "#print('\\n'.join(list_))\n",
    "merge_df = top_uni_bef_merge.merge(times_high_bef_merge, on=title_s, how='inner').sort_values(title_s)\n",
    "merge_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "\n",
    "Find useful insights in the data by performing an exploratory analysis. Can you find a strong correlation between any pair of variables in the dataset you just created? Example: when a university is strong in its international dimension, can you observe a consistency both for students and faculty members?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Question 5\n",
    "\n",
    "Can you find the best university taking in consideration both rankings? Explain your approach.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
